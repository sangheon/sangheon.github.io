---
layout: post
title:  "[번역] NUMA-Aware Memory Allocation for G1 GC"
tags: [G1, Performance, NUMA, JDK 14]
---

기본 Garbage Collector(이하, GC)인 G1 GC는 JDK-14때부터 [JEP-345: NUMA-Aware Memory Allocation for G1](https://bugs.openjdk.java.net/browse/JDK-8210473) 에 의해 NUMA-aware하게 되었습니다[^numa_impl]. 이 글에서는 어떻게 NUMA-aware 구현에 대해 간단히 설명할 예정입니다. 다만, 일반적인 G1 GC 구현에 대해서는 최소한으로 설명하겠습니다.<br>

## NUMA 란?
NUMA는 **Non-Uniform Memory Access**의 약자로 로컬 메모리 액세스가 로컬이 아닌 메모리 액세스보다 빠르다는 것이 요지입니다. 참고로 제 워크스테이션, Xeon E5-2665 2.4GHz에서 로컬 메모리 액세스는 로컬이 아닌 메모리 액세스의 절반이 나옵니다[^my_numactl]. <br>

일반적으로 NUMA-awareness를 추가하게 되면 어느정도의 성능향상을 기대할수 있습니다[^general_numa]. 그래서 Parallel GC는 오래 전에 NUMA-aware를 추가했고 ZGC는 처음부터 NUMA-aware를 염두에두고 개발되었습니다.<br>

## 그렇다면 NUMA-aware 구현 전에는?
G1 GC 알고리즘은 JEP-345에 의한 NUMA-aware하게되기 이전에도 NUMA 노드간에 메모리를 인터리빙(interleaving)했습니다. 이것은 메모리가 커밋되거나 예약될 때, 그 메모리를 액세스하고 있는 쓰레드와 같은 NUMA 노드에 속하도록 조정되는것을 의미합니다. 즉, 우리는 이미 메모리 인터리브의 장점을 활용하고 있었습니다. 이 인터리빙은 UseNUMA command-line option이 활성화되면 자동으로 활성화되는 UseNUMAInterleaving 옵션에 의해 관리됩니다[^numa_interleaving]. 따라서 NUMA-aware 구현으로 인한 성능 향상만을 비교하려면, 패치 전과 후 모두에 -XX:+UseNUMA를 추가해야합니다.<br>

## G1 GC 힙 초기화
G1 GC는 Java 힙을 동일한 크기의 여러 덩어리로 분할 한 후 관리하며 각 덩어리를 G1 heap region이라고합니다 (내부적으로 HeapRegion 혹은 G1HeapRegion이라고 부르기에 G1 heap region이라고 하겠습니다). NUMA 를 활성화한 Java 힙 초기화 시에는 OS에 정해진 NUMA 노드에 각각의 G1 heap region을 할당하도록 요청하는 것입니다. 여기서 정해졌다는 것은 현재 활성화된 NUMA ID를 G1 heap region에게 균등하게 할당하는 것을 의미합니다. 이 할당 요청은 OS에 의해 정상적으로 처리되어 전체 힙이 활성 NUMA 노드 사이에 균등하게 위치한다고 가정합니다. (그림 1)<br>
![Figure 1]({{ site.baseurl }}/assets/posts/g1numa/NUMA_heap_init.png){: class="center_85" width="70%" }<br>

이제 G1 GC heap region이 OS 페이지를 처리하는 방법에 대해 알아볼 차례입니다. G1 GC에서 NUMA ID의 단위는 heap region입니다. 즉, 하나의 heap region, 하나의 덩이리는 동일한 NUMA ID를 갖는 것으로 간주됩니다. 그리고 이것은 OS의 NUMA 할당 단위인 페이지(page)와는 다릅니다. OS 페이지가 G1 heap region 크기보다 작으면 구현은 간단합니다. 하나의 G1 heap region은 여러 OS 페이지로 구성됩니다. 예 : G1 heap region 크기가 1MB이고 페이지 크기가 4KB이면 1 개의 heap region에 256 페이지가 사용됩니다. G1 heap region 크기가 OS 페이지 크기보다 작으면 어떻게 될까요? 이 경우 하나의 페이지가 여러 개의 G1 heap region에 사용됩니다. 예 : G1 heap region 크기가 1MB이고 페이지 크기가 2MB 인 경우 2 개의 heap region에 1 페이지가 사용됩니다 (그림 2). 물론 G1 heap region 크기와 OS 페이지 크기의 경우 한 크기가 다른 크기의 배수여야 합니다.<br>
![Figure 2]({{ site.baseurl }}/assets/posts/g1numa/NUMA_region_page.png){: class="center_85" width="70%" }<br>

## G1 GC 메모리 할당

힙 초기화가 되었으니, 이제 어떻게 메모리가 Java 애플리케이션에 할당되지에 대해 알아보겠습니다.
NUMA-aware 구현 전에는 Java 쓰레드가 JVM에 메모리를 요청하면 G1 GC는 단일 MutatorAllocRegion 인스턴스에서 메모리를 할당합니다[^numa_mutator].
NUMA-aware 구현에서의 G1 GC는 여러 MutatorAllocRegion 인스턴스가 가지고 있습니다 - 1 개의 NUMA 노드 당 1 개의 인스턴스 (그림 3).
따라서 Java 쓰레드가 JVM에 메모리를 요청하면 G1 GC는 **mutator (Java 쓰레드)의 NUMA 노드를 확인**한 다음 **동일한 NUMA 노드를 가진 MutatorAllocRegion에서 메모리를 할당**합니다.<br>
![Figure 3]({{ site.baseurl }}/assets/posts/g1numa/NUMA_mutator_region.png){: class="center_85" width="70%" }
<br>

위의 개념은 Survivor region에서도 똑갑습니다. G1 GC에는 여러 SurvivorGCAllocRegion이 있고, 1 개의 NUMA 노드 당 1 개의 인스턴스가 있습니다. 다만, MutatorAllocRegion과는 다르게 고려해야 할 다른 사항이 있습니다. Young GC가 발생하면, G1 GC는 살아남은 오프젝트들을 survivor region에 복사할 텐데, 이때의 복사 작업을 여러개의 GC 쓰레드에서 하게됩니다[^parallelgcthreads]. 각각의 GC 쓰레드는 이 복사 작업을 위해 고유의 버퍼를 갖고 있는데 이 버퍼를 PLAB(Promotion Local Allocation Buffer)라고 합니다. 각각의 PLAB은 같은 NUMA 노드를 가진 SurvivorGCAllocRegion에서 할당됩니다. 이 PLAB 덕분에 직접 SurvivorGCAllocRegion에서 메모리를 할당 받는 경우에 비해 동기화를 최소화 할 수 있습니다. 이처럼 survivor region은 두가지가 변경되었습니다.<br>
![Figure 4]({{ site.baseurl }}/assets/posts/g1numa/NUMA_survivor_region.png){: class="center_85" width="70%" }
<br>

처음에 전체 Java 힙이 활성 NUMA 노드로 균등하게 분할 될 것이라고 언급했지만 young generation (Eden 및 Survivor region) 만 설명했습니다. 이유는 나머지 old generation은 NUMA-aware하지 않기 때문인데, NUMA-aware하게 해서 테스트 해본 결과, 많은 성능 향상을 이루지 못했기 때문입니다. 이것은 ParallelGC에 NUMA-aware를 추가할때에도 동일합니다. 또한 old generation heap region은 비어있는 heap region을 할당 받기 때문에 상대적으로 균형 잡히도록 heap region을 할당 할 수 있습니다. 추후에라도 가시적인 이점이 있다면 old generation도 NUMA-aware 하도록 변경 할 수 있습니다.<br>


## 로그 메시지
새로 추가된 NUMA-aware 구현은 `numa` 로그 태그에 속합니다. `-Xlog:gc*`로 로그를 프린트할 경우, NUMA의 info 레벨 로그도 프린트됩니다. 그리고 NUMA관련 로그만 보고 싶다면, `-Xlog:numa*={log level}`로 하면 됩니다.<br>

## SpecJBB2015 결과 비교
이제 구현 결과, 성능이 얼마나 향상되었는지 확인해 봅시다. 테스트는 SpecJBB2015로 했습니다[^spec]. NUMA 구현 (JEP-345)은 JDK-14 빌드 24에 포함되어 있으므로 빌드 23과 비교했습니다. 이 외에도, 2 개의 테스트 결과를 포함했습니다. 최신 LTS (Long Term Support)인 JDK-11과 가장 최신인 JDK-15입니다.<br>

![Figure 5]({{ site.baseurl }}/assets/posts/g1numa/NUMA_result_comparison.png){: class="center_85" width="70%" }
<br>

모든 실행은 512GB Java 힙 크기와 4 개의 NUMA 노드 시스템에서 활성화 된 UseNUMA 옵션으로 테스트되었습니다[^test_vmoptions].
Max-jOPS와 Critical-jOPS 모두 JDK-14 b23과 JDK-14 b24 사이에 확실한 성능 향상을 보여주었습니다. **Max-jOPS는 20.64 %**, **Critical-jOPS는 9.52 %** 향상되었습니다. (여기서는 Max-jOPS와 Critical-jOPS의 각 의미에 대해 자세히 설명하지 않겠습니다)<br>
NUMA와는 관련이 없지만 **Max / Critical-jOPS가 JDK 버전이 올라가면서 개선되고 있다**는 점도 유의해볼만 합니다.
테스트 시스템에 NUMA 노드가 많을수록 더 많은 개선이 이루어집니다. 고려해야 할 또 다른 사항은 테스트 할 Java 응용 프로그램이 1 개의 NUMA 노드에서 할당하기에 충분한 작은 Java 힙 크기를 설정하는 경우 크게 개선되지 않을 것입니다. Java 애플리케이션 및 GC 쓰레드의 mutator 쓰레드는 로컬이 아닌 메모리에 거의 액세스하지 않기 때문입니다. 예 : 테스트 컴퓨터가 2 개의 NUMA 노드에 32GB의 메모리를 가진 경우 각 노드에는 16GB의 메모리가 있습니다. Java 애플리케이션이 1GB의 메모리만 사용하는 경우 라면, 모든 메모리는 대부분 1 개의 NUMA 노드에서 할당 될 수 있으므로 성능 향상이 거의 발생 하지 않을 것입니다.<br>

## 마지막으로!
이 글에서 G1 GC에 추가된 NUMA-aware 구현에 대해 간단히 설명했습니다.
백문이 불여일견, NUMA 테스트가 가능하다면 직접 `-XX:+UseNUMA`를 테스트해보는건 어떠실지요?

# &nbsp; {#posts-label}

[^numa_impl]: 리눅스에만 구현됨.
[^my_numactl]: `numactl --hardware` 실행시, local vs. non-local 은 10 vs. 20
[^general_numa]: 특정 환경에서는 성능 향상이 나타나지 않을 수도 있지만 일반적으로 약간의 성능 향상을 기대할 수 있습니다.
[^numa_interleaving]: `UseNUMA` 옵션을 켤 경우 `UseNUMAInterleaving` 옵션은 자동으로 켜지며, NUMA-interleaving은 `UseNUMAInterleaving`으로 제어됩니다.
[^numa_mutator]: `MutatorAllocRegion`는 G1 heap region을 위한 클래스.
[^parallelgcthreads]: 이 GC 쓰레드들은 `-XX:ParallelGCThreads={number}` 옵션에 의해 제어됨.
[^spec]: SPEC® and the benchmark name SPECjbb® are registered trademarks of the Standard Performance Evaluation Corporation. <br>For more information about SPECjbb, see [www.spec.org/jbb2015/](http://www.spec.org/jbb2015/)
[^test_vmoptions]: Full VM options<br>`-Xmx512g -Xms512g -XX:+AlwaysPreTouch -XX:+PrintFlagsFinal -XX:ParallelGCThreads=48> -XX:ConcGCThreads=4 -XX:+UseG1GC -XX:+UseLargePages -XX:+UseNUMA -Xlog:gc*,ergo*=debug:gc.log::filesize=0 -XX:-UseBiasedLocking`








The default Garbage Collector, G1 GC is enhanced on JDK-14 by making its memory allocation to be NUMA-aware by [JEP-345: NUMA-Aware Memory Allocation for G1](https://bugs.openjdk.java.net/browse/JDK-8210473) [^numa_impl]. <br>In this article, I will explain a little bit about its implementation. I will try minimally explain about general G1 GC implementation.<br>

## What is NUMA?
Before deep dive into it, let's remind what is NUMA.<br>
**NUMA stands for Non-Uniform Memory Access** and shortly saying the local memory access is faster than non-local memory access. On my local test, Xeon E5-2665 2.4GHz, local memory access takes half of the non-local memory access[^my_numactl].<br>

Generally, there is no doubt we can expect performance improvement when add NUMA-awareness on the existing Garbage Collector[^general_numa]. In this regard, Parallel GC added NUMA support a long time ago. And ZGC was developed with NUMA-aware in mind.<br>

## Before NUMA-aware implementation?
G1 garbage collector algorithm was interleaving memory among NUMA nodes even before the NUMA-aware implementation was introduced by JEP-345. This means when memory is committed or when reserved, the given memory will be located on the same NUMA node as the thread which is accessing the memory. So we were already taking the advantage of memory interleaving if UseNUMA is enabled[^numa_interleaving]. So when we want to compare performance improvements by the NUMA-aware implementation only, -XX:+UseNUMA should be added for both before the patch and after the patch runs.<br>

## G1 GC heap initialization
G1 GC manages the Java heap after splitting the Java heap into multiple same-sized chunks and each chunk is called the G1 heap region. So what happens during the NUMA enabled Java heap initialization is requesting to OS to locate G1 heap regions on appropriate NUMA nodes. Appropriate here means rotating active NUMA ids on the G1 heap region evenly. The split logic assumes the request will be honored by OS and the given whole heap will be located evenly among the active NUMA nodes. (Figure 1)<br>
![Figure 1]({{ site.baseurl }}/assets/posts/g1numa/NUMA_heap_init.png){: class="center_85" width="70%" }<br>

Someone may have a question about how G1 GC heap regions deal with OS pages. The granularity of NUMA id in G1 GC is the heap region which means one heap region is considered to have the same NUMA id for the heap region. And this is different from the granularity of OS which is page. It is straightforward if the OS page is smaller than the G1 heap region size. One G1 heap region will be consist of multiple OS pages. e.g. if the G1 heap region size is 1MB and the page size is 4KB, 256 pages will be used for 1 heap region. What happens if the G1 heap region size is smaller than the OS page size? In such a case, one large page will be used for multiple G1 heap regions. e.g. if the G1 heap region size is 1MB and the page size is 2MB, 1 page will be used for 2 heap regions (Figure 2). Of course, for G1 heap region size and OS page size, one size should be multiple of the other.<br>
![Figure 2]({{ site.baseurl }}/assets/posts/g1numa/NUMA_region_page.png){: class="center_85" width="70%" }<br>

## G1 GC memory allocation
The basic heap initialization is ready, now let's talk about how memory is allocated to Java application.
Before the NUMA implementation, when a Java thread requests memory to JVM, G1 GC will allocate memory from a single MutatorAllocRegion instance[^numa_mutator].
Now on the NUMA implementation, G1 GC has multiple MutatorAllocRegion instances, 1 instance per 1 NUMA node (Figure 3)
So when a Java thread requests memory to JVM, **G1 GC will check the mutator(Java thread)'s NUMA node** and then **allocate memory from MutatorAllocRegion which has the same NUMA node**.<br>
![Figure 3]({{ site.baseurl }}/assets/posts/g1numa/NUMA_mutator_region.png){: class="center_85" width="70%" }
<br>

We can expect the above concept to Survivor regions as well, G1 GC will have multiple SurvivorGCAllocRegion, 1 instance per 1 NUMA node. Besides, there is another thing to consider. The addition is a buffer used when G1 GC copies survived objects. When young GC happens, G1 GC will copy survived objects to the survivor region and those copying works are done by multiple GC threads[^parallelgcthreads]. Each GC thread has its buffer to allocate the survived objects and this buffer is called PLAB (Promotion Local Allocation Buffer). Each PLAB is allocated from SurvivorGCAllocRegion. With PLAB, G1 GC can minimize synchronization delay to the SurvivorGCAllocRegion compared to directly allocating from SurvivorGCAllocRegion. So there are 2 things to be NUMA-aware for the survivor region (Figure 4).<br>
![Figure 4]({{ site.baseurl }}/assets/posts/g1numa/NUMA_survivor_region.png){: class="center_85" width="70%" }
<br>

In the beginning, I mentioned the whole Java heap will be split evenly to active NUMA nodes but only explained the young generation (Eden and Survivor regions). The remainder, Old generation is not NUMA-aware because making Old generation NUMA-aware didn't bring much improvement on tests. And this decision is the same for ParallelGC. Besides, Old regions will have NUMA ids of empty G1 heap regions which may help to balance memory use among NUMA nodes. We can consider making Old generation NUMA-aware in the future if there are visible benefits.<br>

## Logging
The logging for those newly added implementations are managed by `numa` tag. When you try `-Xlog:gc*`, VM will print NUMA info level logs as well and if you are interested watching only NUMA related logs, `-Xlog:numa*={log level}` is what you need.<br>

## SpecJBB2015 results comparison
It would be interesting to see how much performance improvements have made with G1 GC NUMA changes. SpecJBB2015[^spec] is used for the test. The NUMA implementation (under JEP-345) is integrated on JDK-14 build 24, so comparing with build 23 would be the most interesting. Additionally, there are 2 more test results - from the latest LTS (Long Term Support) which is 11, and from the latest JDK which is 15.<br>

![Figure 5]({{ site.baseurl }}/assets/posts/g1numa/NUMA_result_comparison.png){: class="center_85" width="70%" }
<br>

All runs were tested with 512GB Java heap size and UseNUMA option enabled on 4 NUMA nodes machine [^test_vmoptions].
Both Max-jOPS and Critical-jOPS showed promising improvements between JDK-14 b23 and JDK-14 b24. Max-jOPS is improved by **20.64%** and Critical-jOPS is improved by **9.52%**. (I will not deep dive into each meaning of Max-jOPS and Critical-jOPS here)<br>
Not related to NUMA but one more thing to point out is that **both Max / Critical-jOPS are improving over time**.
I think the more NUMA nodes on a test system, the more improvements. Another thing to consider is if a Java application to test is setting a small Java heap size which is enough to be allocated from 1 NUMA node, we will not see much improvement. Simply because mutator threads on Java application and GC threads are hardly accessing non-local memories. e.g. if the testing host machine has 32GB of memory on 2 NUMA nodes, each node will have 16GB of memory. If a Java application is only using 1GB of memory, all memory can be allocated from 1 NUMA node so improvement may not happen.
<br>

## Lastly!
I tried to explain as easy as possible what I implemented on G1 GC.
If you didn't try command-line option of `-XX:+UseNUMA` after JDK-14 on one NUMA system, you can try it out.

# &nbsp; {#posts-label}

[^numa_impl]: Implemented only on Linux
[^my_numactl]: when run `numactl --hardware`, local vs. non-local is 10 vs. 20
[^general_numa]: In some situations, there might not difference, but generally we can expect some improvements.
[^numa_interleaving]: NUMA-interleaving is managed by `UseNUMAInterleaving` option which is automatically enabled when `UseNUMA` is enabled.
[^numa_mutator]: `MutatorAllocRegion` is an abstracted class to manage G1 heap region.
[^parallelgcthreads]: the number of those GC threads are controlled by `-XX:ParallelGCThreads={number}`.
[^spec]: SPEC® and the benchmark name SPECjbb® are registered trademarks of the Standard Performance Evaluation Corporation. <br>For more information about SPECjbb, see [www.spec.org/jbb2015/](http://www.spec.org/jbb2015/)
[^test_vmoptions]: Full VM options<br>`-Xmx512g -Xms512g -XX:+AlwaysPreTouch -XX:+PrintFlagsFinal -XX:ParallelGCThreads=48> -XX:ConcGCThreads=4 -XX:+UseG1GC -XX:+UseLargePages -XX:+UseNUMA -Xlog:gc*,ergo*=debug:gc.log::filesize=0 -XX:-UseBiasedLocking`
